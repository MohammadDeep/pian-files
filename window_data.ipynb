{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNPS9Tli0rlc5FXse9gfDZ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammadDeep/pian-file-public/blob/main/window_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"GPU is available. Using CUDA...\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"GPU is not available. Using CPU...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CQtD_Vgt-tf",
        "outputId": "f9064d6d-c664-467c-d238-9e3c2e21c7d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available. Using CUDA...\n",
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sbEvhwNttty",
        "outputId": "1ead5336-9032-4581-ec07-14ac457dbac3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: read fiile '/content/drive/MyDrive/dataset/PainMoint/extracted_files/PMED/PMHDB/saved_x_norm,y_norm.pkl'\n",
        "\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/dataset/PainMoint/extracted_files/PMED/PMHDB/saved_x_norm,y_norm.pkl'\n",
        "\n",
        "try:\n",
        "  with open(file_path, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "    print('read ')  # Or process the loaded data as needed\n",
        "except FileNotFoundError:\n",
        "  print(f\"File not found: {file_path}\")\n",
        "except Exception as e:\n",
        "  print(f\"Error loading file: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAjIyjlPaPZh",
        "outputId": "5b1a6e19-e63c-44ef-9fd1-07cbd2c6ce33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "read \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = '/content/drive/MyDrive/dataset/PainMoint/extracted_files/PMED/PMHDB/y_data_have_pain_clear.pkl'\n",
        "\n",
        "try:\n",
        "  with open(file_path, 'rb') as f:\n",
        "    y_norm = pickle.load(f)\n",
        "    print('read ')  # Or process the loaded data as needed\n",
        "except FileNotFoundError:\n",
        "  print(f\"File not found: {file_path}\")\n",
        "except Exception as e:\n",
        "  print(f\"Error loading file: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCEKANOfQzJK",
        "outputId": "eece466f-50a0-498d-f483-f35a36733dea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "read \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhXPz6-xa3Vi",
        "outputId": "d6251aa1-e3e8-42c5-d291-0271adbf34fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J0YQuPTwY8Z-"
      },
      "outputs": [],
      "source": [
        "x_norm,_ = data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test,x_dav, x_train = x_norm[:10], x_norm[10:15], x_norm[15:]\n",
        "y_test,y_dav, y_train = y_norm[:10], y_norm[10:15], y_norm[15:]"
      ],
      "metadata": {
        "id": "sCyEittkyPW-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def window_data(data, window, step):\n",
        "  len_data = len(data)\n",
        "  new_data = []\n",
        "  for i in range(len_data):\n",
        "    print(f'persion : {i + 1}/{len_data}')\n",
        "    data1 = data[i]\n",
        "    len_data1 = data1.shape[0]\n",
        "    n = (len_data1 - window) // step + 1\n",
        "    for i1 in range(n):\n",
        "      new_data.append(torch.tensor(data1[i1*step:i1*step+window], device = device).tolist())\n",
        "\n",
        "\n",
        "  return new_data\n",
        "WINDOW_SIZE = 30 *250\n",
        "STEP = 5 * 250\n",
        "window_x_test = window_data(x_test, WINDOW_SIZE, STEP)\n",
        "window_y_test = window_data(y_test, WINDOW_SIZE, STEP)\n",
        "window_x_dav = window_data(x_dav, WINDOW_SIZE, STEP)\n",
        "window_y_dav = window_data(y_dav, WINDOW_SIZE, STEP)\n",
        "window_x_train = window_data(x_train,WINDOW_SIZE, STEP)\n",
        "window_y_train = window_data(y_train, WINDOW_SIZE, STEP)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwCybsZMrRv1",
        "outputId": "ca1da06d-e2cf-4e0b-9c62-b9c3d2c693f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "persion : 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-f5afcab344a0>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  new_data.append(torch.tensor(data1[i1*step:i1*step+window], device = device).tolist())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "persion : 2/10\n",
            "persion : 3/10\n",
            "persion : 4/10\n",
            "persion : 5/10\n",
            "persion : 6/10\n",
            "persion : 7/10\n",
            "persion : 8/10\n",
            "persion : 9/10\n",
            "persion : 10/10\n",
            "persion : 1/10\n",
            "persion : 2/10\n",
            "persion : 3/10\n",
            "persion : 4/10\n",
            "persion : 5/10\n",
            "persion : 6/10\n",
            "persion : 7/10\n",
            "persion : 8/10\n",
            "persion : 9/10\n",
            "persion : 10/10\n",
            "persion : 1/5\n",
            "persion : 2/5\n",
            "persion : 3/5\n",
            "persion : 4/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# آزادسازی حافظه‌ی کش GPU\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "kUegc4RuwETK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_x_train = torch.tensor(window_x_train, device = device)\n",
        "window_y_train = torch.tensor(window_y_train, device = device)\n",
        "window_x_dav = torch.tensor(window_x_dav, device = device)\n",
        "window_y_dav = torch.tensor(window_y_dav, device = device)\n",
        "window_x_test = torch.tensor(window_x_test, device = device)\n",
        "window_y_test = torch.tensor(window_y_test, device = device)"
      ],
      "metadata": {
        "id": "I_Pv9xPLtd3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# Save the windowed data to a file in Google Drive\n",
        "save_path = '/content/drive/MyDrive/dataset/PainMoint/extracted_files/PMED/PMHDB/windowed_data_window30S_step5S.pkl'\n",
        "try:\n",
        "  with open(save_path, 'wb') as f:\n",
        "    pickle.dump((window_x_train, window_y_train, window_x_dav, window_y_dav, window_x_test, window_y_test), f)\n",
        "    print(f\"Windowed data saved to: {save_path}\")\n",
        "except Exception as e:\n",
        "  print(f\"Error saving windowed data: {e}\")\n"
      ],
      "metadata": {
        "id": "LddFct3Hw3rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oac24Tu-0VRH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}