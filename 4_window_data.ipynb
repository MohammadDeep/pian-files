{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MohammadDeep/pian-file-public/blob/main/4_window_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kTQpn_WYoIx6"
   },
   "outputs": [],
   "source": [
    "file_path1 = r'C:\\Users\\pc\\Desktop\\COADE\\save_file\\extracted_files\\PMED\\PMHDB\\saved_x_norm,y_norm.pkl'\n",
    "file_path = r'C:\\Users\\pc\\Desktop\\COADE\\save_file\\extracted_files\\PMED\\PMHDB\\y_scali_1000.pkl'\n",
    "scali = 1000\n",
    "save_path =r'C:\\Users\\pc\\Desktop\\COADE\\save_file\\extracted_files\\PMED\\PMHDB\\windowed_data_window1000_step1000.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CQtD_Vgt-tf",
    "outputId": "959d7a93-10f8-420f-c27d-d3a2e3f53676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. Using CUDA...\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "  print(\"GPU is available. Using CUDA...\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"GPU is not available. Using CPU...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_sbEvhwNttty",
    "outputId": "d066fb6a-2a82-4bd1-e03a-d861ba9db521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tAjIyjlPaPZh",
    "outputId": "5f09eaad-2a0f-4cfb-e307-4568948b2161"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read \n"
     ]
    }
   ],
   "source": [
    "# prompt: read fiile '/content/drive/MyDrive/dataset/PainMoint/extracted_files/PMED/PMHDB/saved_x_norm,y_norm.pkl'\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "  with open(file_path1, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    print('read ')  # Or process the loaded data as needed\n",
    "except FileNotFoundError:\n",
    "  print(f\"File not found: {file_path1}\")\n",
    "except Exception as e:\n",
    "  print(f\"Error loading file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "J0YQuPTwY8Z-",
    "outputId": "c97dddc1-0b8d-4250-804d-8aa6d0f53385"
   },
   "outputs": [],
   "source": [
    "x_norm,_ = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCEKANOfQzJK",
    "outputId": "c5b0700b-4833-409f-dfba-233d74be0d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "try:\n",
    "  with open(file_path, 'rb') as f:\n",
    "    y_norm = pickle.load(f)\n",
    "    print('read ')  # Or process the loaded data as needed\n",
    "except FileNotFoundError:\n",
    "  print(f\"File not found: {file_path}\")\n",
    "except Exception as e:\n",
    "  print(f\"Error loading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhXPz6-xa3Vi",
    "outputId": "5f3211e4-30b1-4da2-a8f5-88d9ce2f5523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_norm)):\n",
    "    x_len = x_norm[i].shape[0] // scali\n",
    "    y_len = y_norm[i].shape[0]\n",
    "    min_len = min(x_len, y_len)\n",
    "    x_norm[i] = x_norm[i][: (min_len * scali)]\n",
    "    y_norm[i] = y_norm[i][: min_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 364)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm[10].shape[0]//1000, y_norm[10].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "sCyEittkyPW-"
   },
   "outputs": [],
   "source": [
    "x_test,x_dav, x_train = x_norm[:10], x_norm[10:15], x_norm[15:]\n",
    "y_test,y_dav, y_train = y_norm[:10], y_norm[10:15], y_norm[15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "TwCybsZMrRv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persion : 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_8152\\2666121817.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  new_data.append(torch.tensor(data1[i1*step:i1*step+window], device = device).tolist())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persion : 2/10\n",
      "persion : 3/10\n",
      "persion : 4/10\n",
      "persion : 5/10\n",
      "persion : 6/10\n",
      "persion : 7/10\n",
      "persion : 8/10\n",
      "persion : 9/10\n",
      "persion : 10/10\n",
      "persion : 1/10\n",
      "persion : 2/10\n",
      "persion : 3/10\n",
      "persion : 4/10\n",
      "persion : 5/10\n",
      "persion : 6/10\n",
      "persion : 7/10\n",
      "persion : 8/10\n",
      "persion : 9/10\n",
      "persion : 10/10\n",
      "persion : 1/5\n",
      "persion : 2/5\n",
      "persion : 3/5\n",
      "persion : 4/5\n",
      "persion : 5/5\n",
      "persion : 1/5\n",
      "persion : 2/5\n",
      "persion : 3/5\n",
      "persion : 4/5\n",
      "persion : 5/5\n",
      "persion : 1/37\n",
      "persion : 2/37\n",
      "persion : 3/37\n",
      "persion : 4/37\n",
      "persion : 5/37\n",
      "persion : 6/37\n",
      "persion : 7/37\n",
      "persion : 8/37\n",
      "persion : 9/37\n",
      "persion : 10/37\n",
      "persion : 11/37\n",
      "persion : 12/37\n",
      "persion : 13/37\n",
      "persion : 14/37\n",
      "persion : 15/37\n",
      "persion : 16/37\n",
      "persion : 17/37\n",
      "persion : 18/37\n",
      "persion : 19/37\n",
      "persion : 20/37\n",
      "persion : 21/37\n",
      "persion : 22/37\n",
      "persion : 23/37\n",
      "persion : 24/37\n",
      "persion : 25/37\n",
      "persion : 26/37\n",
      "persion : 27/37\n",
      "persion : 28/37\n",
      "persion : 29/37\n",
      "persion : 30/37\n",
      "persion : 31/37\n",
      "persion : 32/37\n",
      "persion : 33/37\n",
      "persion : 34/37\n",
      "persion : 35/37\n",
      "persion : 36/37\n",
      "persion : 37/37\n",
      "persion : 1/37\n",
      "persion : 2/37\n",
      "persion : 3/37\n",
      "persion : 4/37\n",
      "persion : 5/37\n",
      "persion : 6/37\n",
      "persion : 7/37\n",
      "persion : 8/37\n",
      "persion : 9/37\n",
      "persion : 10/37\n",
      "persion : 11/37\n",
      "persion : 12/37\n",
      "persion : 13/37\n",
      "persion : 14/37\n",
      "persion : 15/37\n",
      "persion : 16/37\n",
      "persion : 17/37\n",
      "persion : 18/37\n",
      "persion : 19/37\n",
      "persion : 20/37\n",
      "persion : 21/37\n",
      "persion : 22/37\n",
      "persion : 23/37\n",
      "persion : 24/37\n",
      "persion : 25/37\n",
      "persion : 26/37\n",
      "persion : 27/37\n",
      "persion : 28/37\n",
      "persion : 29/37\n",
      "persion : 30/37\n",
      "persion : 31/37\n",
      "persion : 32/37\n",
      "persion : 33/37\n",
      "persion : 34/37\n",
      "persion : 35/37\n",
      "persion : 36/37\n",
      "persion : 37/37\n"
     ]
    }
   ],
   "source": [
    "def window_data(data, window, step):\n",
    "  len_data = len(data)\n",
    "  new_data = []\n",
    "  for i in range(len_data):\n",
    "    print(f'persion : {i + 1}/{len_data}')\n",
    "    data1 = data[i]\n",
    "    len_data1 = data1.shape[0]\n",
    "    n = (len_data1 - window) // step + 1\n",
    "    for i1 in range(n):\n",
    "      new_data.append(torch.tensor(data1[i1*step:i1*step+window], device = device).tolist())\n",
    "\n",
    "\n",
    "  return new_data\n",
    "WINDOW_SIZE = scali\n",
    "STEP = scali\n",
    "window_x_test = window_data(x_test, WINDOW_SIZE, STEP)\n",
    "window_y_test = window_data(y_test, 1, 1)\n",
    "window_x_dav = window_data(x_dav, WINDOW_SIZE, STEP)\n",
    "window_y_dav = window_data(y_dav, 1, 1)\n",
    "window_x_train = window_data(x_train,WINDOW_SIZE, STEP)\n",
    "window_y_train = window_data(y_train, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "kUegc4RuwETK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# آزادسازی حافظه‌ی کش GPU\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "I_Pv9xPLtd3-"
   },
   "outputs": [],
   "source": [
    "window_x_train = torch.tensor(window_x_train, device = device)\n",
    "window_y_train = torch.tensor(window_y_train, device = device)\n",
    "window_x_dav = torch.tensor(window_x_dav, device = device)\n",
    "window_y_dav = torch.tensor(window_y_dav, device = device)\n",
    "window_x_test = torch.tensor(window_x_test, device = device)\n",
    "window_y_test = torch.tensor(window_y_test, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "LddFct3Hw3rP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowed data saved to: C:\\Users\\pc\\Desktop\\COADE\\save_file\\extracted_files\\PMED\\PMHDB\\windowed_data_window1000_step1000.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Save the windowed data to a file in Google Drive\n",
    "\n",
    "try:\n",
    "  with open(save_path, 'wb') as f:\n",
    "    pickle.dump((window_x_train, window_y_train, window_x_dav, window_y_dav, window_x_test, window_y_test), f)\n",
    "    print(f\"Windowed data saved to: {save_path}\")\n",
    "except Exception as e:\n",
    "  print(f\"Error saving windowed data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "oac24Tu-0VRH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "try:\n",
    "  with open(save_path, 'rb') as f:\n",
    "    window_x_train, window_y_train, window_x_dav, window_y_dav, window_x_test, window_y_test = pickle.load(f)\n",
    "    print('read ')  # Or process the loaded data as needed\n",
    "except FileNotFoundError:\n",
    "  print(f\"File not found: {file_path1}\")\n",
    "except Exception as e:\n",
    "  print(f\"Error loading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1807, 1000, 9]), torch.Size([1807, 1, 2]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_x_dav.shape, window_y_dav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOCBGtd01MyqDSBE/xz13hC",
   "gpuType": "L4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
